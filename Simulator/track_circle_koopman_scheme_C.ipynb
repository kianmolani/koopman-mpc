{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Neural network training and model selection\n",
    "\n",
    "Here, we define the neural network and perform training to learn the linear operators $A$, $B$, and $C$. Training data is produced in `build_training_datasets.ipynb` and imported here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_dim = 13 # dimension of quadrotor state vector in state-space (fixed)\n",
    "control_input_dim = 4 # number of control inputs, equal to the number of quadrotor motors (fixed)\n",
    "no_lifting_fcts = 10 # size of lifting dictionary\n",
    "meta_space_dim = state_space_dim * no_lifting_fcts # dimension of state-vector in lifted space\n",
    "\n",
    "# encoder model\n",
    "\n",
    "encoder_input_dim = state_space_dim # number of input features to encoder, equal to dimension of state-space vector\n",
    "encoder_no_hidden_layers = 3 # number of hidden layers in encoder \n",
    "encoder_width = 80 # width of hidden layers in encoder\n",
    "encoder_output_dim = meta_space_dim # dimension of output layer, equal to dimension of state-vector in lifted space\n",
    "\n",
    "# decoder model\n",
    "\n",
    "decoder_input_dim = meta_space_dim # number of input features to decoder, equal to dimension of meta-space vector\n",
    "decoder_no_hidden_layers = 3 # number of hidden layers in decoder\n",
    "decoder_width = 80 # width of hidden layers in decoder\n",
    "decoder_output_dim = state_space_dim # dimension of output layer, equal to dimension of state-space vector\n",
    "\n",
    "# operator model ('A' matrix)\n",
    "\n",
    "operator_A_input_dim = meta_space_dim\n",
    "operator_A_output_dim = meta_space_dim\n",
    "\n",
    "# operator model ('B' matrix)\n",
    "\n",
    "operator_B_input_dim = state_space_dim\n",
    "operator_B_output_dim = meta_space_dim\n",
    "\n",
    "# operator model ('C' matrix)\n",
    "\n",
    "operator_C_input_dim = control_input_dim\n",
    "operator_C_output_dim = meta_space_dim\n",
    "\n",
    "# toggle loss terms\n",
    "\n",
    "reconstruction_loss = False # loss associated to autoencoder reconstruction ability\n",
    "linear_dynamics_loss = False # loss associated to Koopman operator's ability to propagate dynamics linearly in lifted space\n",
    "state_prediction_loss = True # loss associated to network's ability to perform accurate state prediction\n",
    "\n",
    "# import settings\n",
    "\n",
    "file_to_import = '02202024_05.pk1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "data_dir = os.getcwd() + '/output/data/'\n",
    "\n",
    "with open(data_dir + file_to_import, 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)\n",
    "\n",
    "data['full_traj'] = data['full_traj'].astype(np.float32)\n",
    "data['U'] = data['U'].astype(np.float32)\n",
    "\n",
    "# convert data to torch tensors and define auxiliary information\n",
    "\n",
    "X = torch.tensor(data['full_traj'], device=device).T\n",
    "U = torch.tensor(data['U'], device=device).T\n",
    "\n",
    "indices = data['indices']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive disturbance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quad import Quad\n",
    "\n",
    "# define quadrotor and world parameters\n",
    "\n",
    "m = 1.0 # quadrotor mass in [kg]\n",
    "J = np.array([.03, .03, .06]) # quadrotor moment of inertia vector in [kg⋅m⋅m]\n",
    "l = 0.235 # length between motor and quadrotor CoG in [m]\n",
    "c = 0.013 # torque generated by each motor in direction of quadrotor z-axis in [N⋅m]\n",
    "T_max = 10 # max thrust generated by each motor in [N]\n",
    "g = 9.81 # gravitational acceleration of world in [m/s/s]\n",
    "\n",
    "quad = Quad(m=m, J=J, l=l, c=c, T_max=T_max, g=g, drag=False)\n",
    "\n",
    "# build disturbance data matrix\n",
    "\n",
    "W = np.zeros((X.shape[0], X.shape[1])) # disturbance data matrix\n",
    "simulation_dt = 5e-4 # integration step size in [s]\n",
    "\n",
    "for start, end in indices:\n",
    "    quad.set_state(*np.split(np.array(X[start][:]), [3, 7, 10]))\n",
    "\n",
    "    for i in range(end-start):\n",
    "        quad.update(np.array(U[start+i][:]), simulation_dt)\n",
    "\n",
    "        # compute disturbance\n",
    "\n",
    "        x_pred = quad.get_state()\n",
    "        x_act = np.array(X[start+i+1])\n",
    "        W[start+i][:] = x_act - x_pred\n",
    "\n",
    "        if i == end-start-1:\n",
    "            W[start+i+1][:] = np.full((1, X.shape[1]), np.nan)\n",
    "\n",
    "W = W[~np.isnan(W).any(axis=1)]\n",
    "\n",
    "# construct eDMD matrices\n",
    "\n",
    "Y = torch.tensor(W[1:,:].astype(np.float32), device=device).T\n",
    "W = torch.tensor(W[:-1,:].astype(np.float32), device=device).T\n",
    "\n",
    "# other\n",
    "\n",
    "U = U[~torch.isnan(U).any(dim=1)]\n",
    "\n",
    "for i in indices:\n",
    "    X = torch.cat((X[:i[1]], X[i[1] + 1:]), dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import Encoder, Decoder, Operator, Adder, Predictor\n",
    "\n",
    "encoder = Encoder(encoder_input_dim, encoder_no_hidden_layers, encoder_width, encoder_output_dim)\n",
    "adder = Adder(Operator(operator_A_input_dim, operator_A_output_dim), Operator(operator_B_input_dim, operator_B_output_dim), Operator(operator_C_input_dim, operator_C_output_dim))\n",
    "decoder = Decoder(decoder_input_dim, decoder_no_hidden_layers, decoder_width, decoder_output_dim)\n",
    "predictor = Predictor(encoder, adder, decoder, state_space_dim, state_space_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commence training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define loss criterion\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# define optimizer\n",
    "\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=0.001)\n",
    "\n",
    "# define number of epochs and perform training\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "epoch_num = []; loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    target = Y\n",
    "    output = predictor(W.T, X, U[:-1,:])\n",
    "\n",
    "    # compute loss\n",
    "\n",
    "    loss = criterion(target, output)\n",
    "\n",
    "    # perform backpropagation\n",
    "\n",
    "    predictor.zero_grad() # zero the gradient buffers\n",
    "    loss.backward()\n",
    "    optimizer.step() # perform the update\n",
    "\n",
    "    # print the loss for tracking progress\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "    epoch_num.append(epoch)\n",
    "    loss_history.append(loss.item() * 100) # express as a percentage\n",
    "\n",
    "# print loss curve to assess convergence\n",
    "\n",
    "plt.plot(epoch_num, loss_history)\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss (%)\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#################################################################################################\n",
    "# WARNING: WHY IS LOSS > 100% AT THE START OF TRAINING? THIS SHOULD NOT BE POSSIBLE BY DEFINITION\n",
    "#################################################################################################\n",
    "\n",
    "# extract A and B matrices from trained predictor neural network and convert to numpy arrays\n",
    "\n",
    "A = predictor.adder.A.operator[0].weight.data.numpy()\n",
    "B = predictor.adder.B.operator[0].weight.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Trajectory tracking using Koopman-MPC\n",
    "\n",
    "Here, we pair our learned Koopman model (captured by matrices $A$ and $B$) with MPC in order to perform quadrotor trajectory tracking. We implement here the same trajectory tracking problem that was implemented in `track_circular_nominal.ipynb`.\n",
    "\n",
    "Notes and to-do:\n",
    "\n",
    "- Consider ways to properly initialize and possibly vary (across our MPC time-horizon) $Q$ and $R$ weighing matrices. Some links that may be useful: https://www.researchgate.net/post/how_to_determine_the_values_of_the_control_matrices_Q_and_R_for_the_LQR_strategy_when_numerically_simulating_the_semi-active_TLCD. Where did I get the idea that $Q$ should be `np.ones()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure simulation settings / world darta? / MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# toggle simulation disturbances\n",
    "\n",
    "simulation_disturbances = {\n",
    "    \"drag\": True,\n",
    "}\n",
    "    \n",
    "# define quadrotor and world properties\n",
    "\n",
    "m = 1.0 # quadrotor mass in [kg]\n",
    "J = np.array([.03, .03, .06]) # quadrotor moment of inertia vector in [kg⋅m⋅m]\n",
    "l = 0.235 # length between motor and quadrotor CoG in [m]\n",
    "c = 0.013 # torque generated by each motor in direction of quadrotor z-axis in [N⋅m]\n",
    "T_max = 10 # max thrust generated by each motor in [N]\n",
    "g = 9.81 # gravitational acceleration of world in [m/s/s]\n",
    "init_pos = np.array([0.0, 1.0, 1.0]) # initial position of quadrotor\n",
    "\n",
    "# define drag coefficients\n",
    "\n",
    "rotor_drag = np.array([0.3, 0.3, 0.0])[:, np.newaxis] # rotor drag coefficients in [kg/m]\n",
    "aero_drag = 0.08 # aerodynamic drag coefficient in [kg/m]\n",
    "\n",
    "# define MPC and RK4 settings\n",
    "\n",
    "t_horizon = 1.0 # prediction horizon in [s]\n",
    "n_mpc_nodes = 10 # number of control nodes within horizon\n",
    "Q = np.array([10, 10, 10, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]) # weighing matrix for quadratic cost function\n",
    "R = np.array([0.1, 0.1, 0.1, 0.1]) # weighing matrix for quadratic cost function\n",
    "simulation_dt = 5e-4 # integration step size in [s]\n",
    "\n",
    "# define trajectory settings\n",
    "\n",
    "traj_radius = 5 # radius of trajectory in [m]\n",
    "traj_v_max = 10 # maximum speed at peak velocity in [m/s]\n",
    "traj_a_lin = 1 # linear acceleration of trajectory in [m/s/s]\n",
    "reference_over_sampling = 5\n",
    "\n",
    "# toggle plotting features\n",
    "\n",
    "animate_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate reference trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from quad import Quad\n",
    "from quad_mpc_koopman import QuadMPCKoopman\n",
    "from trajectories import check_trajectory, loop_trajectory\n",
    "\n",
    "# instantiate Quad and QuadMPC objects\n",
    "\n",
    "quad = Quad(m=m, J=J, l=l, c=c, T_max=T_max, g=g, rotor_drag=rotor_drag, aero_drag=aero_drag, drag=simulation_disturbances[\"drag\"])\n",
    "quad_mpc = QuadMPCKoopman(quad=quad, lifted_state_dim=meta_space_dim, no_control_inputs=control_input_dim, A=A, B=B, t_horizon=t_horizon, n_nodes=n_mpc_nodes, Q=Q, R=R, encoder=predictor.encoder)\n",
    "\n",
    "# generate reference trajectory and control policy (burrowed entirely from https://github.com/uzh-rpg/data_driven_mpc/tree/main)\n",
    "\n",
    "control_period = t_horizon / (n_mpc_nodes * reference_over_sampling) # sampling period of trajectory\n",
    "\n",
    "reference_traj, reference_timestamps, reference_u = loop_trajectory(\n",
    "    quad=quad, discretization_dt=control_period, radius=traj_radius, \n",
    "    lin_acc=traj_a_lin, clockwise=True, yawing=False, v_max=traj_v_max, plot=True)\n",
    "\n",
    "if not check_trajectory(reference_traj, reference_timestamps, plot=False):\n",
    "    print(\"Reference trajectory integrity check failed!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# compute reference speed\n",
    "\n",
    "reference_speed = np.linalg.norm(reference_traj[:,7:10], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.math import separate_variables\n",
    "from utils.mpc import get_reference_chunk\n",
    "\n",
    "# initialize quadrotor state\n",
    "\n",
    "initial_state = np.split(reference_traj[0, :], [3, 7, 10])\n",
    "initial_state[0] = init_pos\n",
    "quad.set_state(*initial_state)\n",
    "\n",
    "n_quad_states = len(quad.get_state())\n",
    "n_control_states = len(quad.u)\n",
    "\n",
    "# begin simulation\n",
    "\n",
    "quad_traj = np.zeros([len(reference_timestamps), n_quad_states]) # store quadrotor trajectory\n",
    "opt_u = reference_u[0, :] # optimal control action to be applied in MPC loop\n",
    "opt_u_history = np.zeros([len(reference_timestamps), n_control_states]) # store optimal control action history\n",
    "tracking_error = np.zeros(len(reference_timestamps)) # store tracking error\n",
    "\n",
    "print(\"\\nRunning MPC loop ...\")\n",
    "\n",
    "for i in range(len(reference_timestamps)):\n",
    "    \n",
    "    # retrieve and save quadrotor state\n",
    "\n",
    "    quad_current_state = quad.get_state()\n",
    "    quad_traj[i, :] = np.expand_dims(quad_current_state, axis=0)\n",
    "\n",
    "    # compute tracking error\n",
    "\n",
    "    tracking_error[i] = np.linalg.norm(reference_traj[i, :3] - quad_traj[i, :3])\n",
    "\n",
    "    # get the chunk of trajectory required for the current optimization (burrowed entirely from https://github.com/uzh-rpg/data_driven_mpc/tree/main)\n",
    "\n",
    "    ref_traj_chunk, ref_u_chunk = get_reference_chunk(reference_traj, reference_u, i, n_mpc_nodes, reference_over_sampling)\n",
    "\n",
    "    # lift and set the reference for the OCP\n",
    "    \n",
    "    ref_traj_chunk_temp = separate_variables(ref_traj_chunk)\n",
    "    lifted_ref_traj_chunk = predictor.encoder(torch.tensor(ref_traj_chunk_temp.astype(np.float32), device=device))\n",
    "    \n",
    "    quad_mpc.set_reference(z_ref=lifted_ref_traj_chunk, u_ref=ref_u_chunk)\n",
    "\n",
    "  a  # solve OCP to retrieve optimized control and state sequences\n",
    "    \n",
    "    u_opt_acados, z_opt_acados = quad_mpc.optimize()\n",
    "\n",
    "    # select first set of control actions as the control to apply to the plant\n",
    "\n",
    "    opt_u = u_opt_acados[:4]\n",
    "    opt_u_history[i, :] = np.reshape(opt_u, (1, -1)) # why is 'np.reshape' needed here?\n",
    "    \n",
    "    # apply control action to quadrotor and update state\n",
    "\n",
    "    simulation_time = 0.0\n",
    "    while simulation_time < control_period:\n",
    "        quad.update(opt_u, simulation_dt)\n",
    "        simulation_time += simulation_dt\n",
    "\n",
    "quad_current_state = quad.get_state()\n",
    "quad_traj[-1, :] = np.expand_dims(quad_current_state, axis=0)\n",
    "\n",
    "# compute tracking RMSE\n",
    "\n",
    "tracking_rmse = np.mean(np.sqrt(np.sum((reference_traj[:, :3] - quad_traj[:, :3]) ** 2, axis=1)))\n",
    "\n",
    "# save trajectory data in a format tailored for EDMD algorithms\n",
    "\n",
    "dir = '/Users/kianmolani/Dropbox/Academia/U-M/Research & Development/Project JASE/code/Python/Simulator/output/data/'\n",
    "\n",
    "np.save(dir + \"quad_traj\", quad_traj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
